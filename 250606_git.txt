머신러닝의 지도학습.. --> 학습데이터 입력 --> 학습 --> 예측--> 평가
분야(task)
분류 ==> 어떤 Label(정답)에 속할 지를 예측
ex ) 품종 분류, 종양 분류(양성, 악성)
--> 즉, 분류는 불연속적인 값을 예측..

회귀 --> 연속적인 값을 예측
ex ) 주가 예측

학습 과정
1. 데이터 분할
학습용 (train data)과 평가용 (test data)를 6:4 ~ 8:2로 분할한다.
함수 : train_test_split(), sklearn.model_selection
이때 X(Feature)와 y(Label)로 데이터를 수동으로 분할 시켜야한다,

모델 평가 척도 --> 실무에서 매우 중요
1. accuracy(정확도) ==> 실무에서 안쓰임, 부정확보단 답이 틀려도 틀린답이 정확하면
정확도가 올라감.

2. recall(재현율) --> 실제 정답중에 정확히 맞춘 비율..
True Recall = 민감도 --> TP/(TP +FN)
*FN --> 잘못된 네거티브 이므로, 실제로는 정답값이라는 것.
False Recall = 특이도 --> TN / (FP + TN)
*FP --> 잘못된 포지티브 이므로, 실제로는 오답값이라는 것.

====> RECALL은 실제 정답의 관점에서 정답의 비율로 보는것이다.

3.  Precision(정밀도)
<모델>이 정답으로 예측한 것 중에서 실제로 맞춘 비율

====> PRECISION은 모델의 관점에서 정답의 비율을 보는것이다.

F1 - Score ( 정밀도와 재현율의 조화 평균)
한쪽으로 치우친 모델이 아닌
정답별로 조화로운 모델은 찾는 것..

MSE / RMSE
mean_square_error ==> 제곱 오차
root_mean_square_error ==> 제곱근 오차 
rmse가 오차를 더 정확히 예측

모델 학습 이후 성능
일반화 (generalization)
새로운 데이터에 대해 정확한 예측 또는 분류 성능을 보이는 능력

과대적합(Overfitting)
모델이 학습 데이터의 노이즈, 특징 없는 패턴까지 모두 학습..
-> 학습데이터에 관해서는 매우 높은 정확도
but 새로운 데이터에 대해서는 성능 매우 떨어짐..

원인 : 학습 데이터가 너무 적거나, 그에 비해 모델의 복잡도가 너무 높을 때
ex ) 조건 : 45세 이상, 자녀 3 미만, 이혼x 고객 --> 요트를 산다(예측)

이걸 해결하기 위해서는
hyperparameter에서 max_depth를 정해야한다.

과소 적합은 반대로 모델이 너무 단순하여, 학습데이터의 기본적인 패턴조차 제대로 학습 x
